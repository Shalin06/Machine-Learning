# -*- coding: utf-8 -*-
"""B21CS070_Lab_Assignment_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qU7-OTdtK9Yc4PjJ1h-nNuiZPazwZiUT

# Lab 6
"""

import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn.ensemble import BaggingClassifier as BC
from sklearn.model_selection import train_test_split as tts
from sklearn.datasets import fetch_olivetti_faces
import random
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
from sklearn.metrics import accuracy_score
from sklearn.datasets import make_moons
from sklearn.svm import SVC

"""## Problem 1

### Preprocessing
"""

columns = ["ID","RI","Na","Mg","Al","Si","K","Ca","Ba","Fe","Type"]
dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data',names = columns)
dataset

for i in columns:
  print(dataset[i].isnull().values.any())
dataset.info()

sns.pairplot(data = dataset.drop("ID",axis = 1),hue = "Type")

plt.rcParams["figure.figsize"] = (5,5)
for i in columns:
  if(i=="ID"):
    continue
  else:
    sns.distplot(dataset[i])
    plt.show()

plt.rcParams["figure.figsize"] = (10,10)
sns.heatmap(dataset.corr(),cmap = "RdYlBu",annot = True)
plt.show()

dataset2 = dataset.drop(["ID","Type"],axis = 1)

"""### Part a)

"""

X = dataset2.copy()
Y = dataset["Type"]
model = KMeans(n_clusters = 7)
labels = model.fit_predict(X)
labels

label_0 = X[labels == 0]
label_1 = X[labels == 1]
label_2 = X[labels == 2]
label_3 = X[labels == 3]
label_4 = X[labels == 4]
label_5 = X[labels == 5]
label_6 = X[labels == 6]
label_i = []
label_i.append(label_0)
label_i.append(label_1)
label_i.append(label_2)
label_i.append(label_3)
label_i.append(label_4)
label_i.append(label_5)
label_i.append(label_6)

plt.rcParams["figure.figsize"] = (20,20)
# plt.rcParams['figure.constrained_layout.use'] = True
# plt.subplots(layout="constrained")
# plt.rcParams['figure.max_open_warning'] = 50
cols = list(X.columns)
colors = ['red','blue','green','yellow','orange','violet','pink']
cnt = 0
centroids = model.cluster_centers_
# fig, axs = plt.subplots(6,6)
fig = plt.figure(figsize =(20, 20))
# ax = Subplot(fig, 111)
# print(centroids)
# def example_plot(ax):
for j in range(len(cols)):
  for k in range(j,len(cols)):
    if(j == k):
      continue
    else:
      cnt += 1
      ax = fig.add_subplot(6, 6, cnt)
      for i in range(0,7):
        sns.scatterplot(x = label_i[i][cols[j]], y = label_i[i][cols[k]], color = colors[i],label = i,ax= ax)
      ax.scatter(centroids[:,j],centroids[:,k], marker = "*",s = 50,color = 'black')
      ax.set_xlabel(cols[j])
      ax.set_ylabel(cols[k])
      ax.legend()
# for ax in axs.flat:
#     example_plot(ax)
print(cnt)
plt.show()

"""### Part b)"""

plt.rcParams["figure.figsize"] = (20,10)
plt.figure(figsize = (20, 10))
score_arr = []
arr=[]
for i in range(2,9):
  KMean= KMeans(n_clusters=i,n_init = 10)
  label=KMean.fit_predict(X)
  ax = plt.subplot(2,4,i-1)
  sns.scatterplot(x = X[cols[0]], y =X[cols[1]],hue=label,palette='bright',ax = ax)
  score_arr.append(silhouette_score(X, label))
  arr.append(i)
  # plt.subplot(2,4,i-1)
  plt.title("Silhouette Score(n = "+str(i)+"):"+ str(silhouette_score(X.to_numpy(), label)))
plt.show()
plt.rcParams["figure.figsize"] = (5,5)
plt.plot(arr,score_arr)
plt.ylabel("Silhouette Score")
plt.xlabel("n_clusters")

"""We can say that for n_clusters if Silhouette score is minimum for that n_cluster value then it is the optimal value of k.

### Part c)
"""

Sum_of_squared_distances = []
for num_clusters in range(1,10) :
 kmeans = KMeans(n_clusters=num_clusters,n_init = 10)
 kmeans.fit(X)
 Sum_of_squared_distances.append(kmeans.inertia_)
plt.plot(range(1,10),Sum_of_squared_distances,'bx-')
plt.xlabel('Values of K') 
plt.ylabel('Sum of squared distances/Inertia') 
plt.title('Elbow Method For Optimal k')
plt.show()

"""### Part d)"""

X_train, X_test, Y_train, Y_test = tts(X, Y, test_size=0.3, random_state=42)
acc_arr = []
for i in range(1,4):
  knn_model = KNN(n_neighbors=i)
  final_model = BC(estimator=knn_model)
  final_model.fit(X_train,Y_train)
  acc_arr.append(final_model.score(X_test,Y_test))
bagging = BC(estimator = SVC())
bagging.fit(X_train,Y_train)
print(bagging.score(X_test,Y_test))
plt.scatter(range(1,4),acc_arr)
plt.xlabel("K")
plt.ylabel("accuracy")

"""## Problem 2

### Preprocessing
"""

olive_data = fetch_olivetti_faces()
olive_data

dataset = pd.DataFrame(data = olive_data.data)
dataset["Class"] = olive_data.target
dataset = dataset.dropna()
dataset

"""### Part a) and b)"""

class Kmeans_scratch_ver2:
  def __init__(self,k,init_centres = [],max_iter = 100):
    self._k = k
    self._centres = init_centres
    self._max_iter = max_iter
    
  def _euclidean_distance(self,point,dataset):
    dis = np.sqrt(np.sum((point-dataset)**2,axis = 1))
    return dis

  def fit(self,X):

    n_provided_centres = len(self._centres)
    if(n_provided_centres == 0):
      ind = np.random.choice(range(len(X)), size=1)
      self._centres = X[ind]
      n_provided_centres = 1

    if(n_provided_centres != self._k):

      for _ in range(self._k - n_provided_centres):

        
        dists = np.sum([self._euclidean_distance(centroid,X) for centroid in self._centres],axis = 0)
        
        dists /= np.sum(dists)
        
        new_centroid_idx = np.random.choice(range(len(X)), size=1, p=dists)[0] 
        self._centres = np.r_[self._centres,[X[new_centroid_idx]]]
    

    for i in range(self._max_iter):
      
      clusters = [[] for _ in range(self._k)]
      for x in X:
        dist = self._euclidean_distance(x,self._centres)
        indx = np.argmin(dist)
        clusters[indx].append(x)

      prev_centroids = self._centres
      self._centres = [np.mean(cluster,axis = 0) for cluster in clusters] 

      for i,centre in enumerate(self._centres):
        if(np.isnan(centre).any()):
          self._centres[i] = prev_centroids[i]
      
      if(np.allclose(self._centres, prev_centroids)):
        break

  def predict(self,X):
    self.centres_of_points = []
    self.centres_indx_of_points = []
    for x in X:
      dists = self._euclidean_distance(x,self._centres)
      centroid_ind = np.argmin(dists)
      self.centres_of_points.append(self._centres[centroid_ind])
      self.centres_indx_of_points.append(centroid_ind)
    return self.centres_of_points,self.centres_indx_of_points

  def count_of_points(self):
    elements_count = {}
    for element in self.centres_indx_of_points:
      if element in elements_count:
          elements_count[element] += 1
      else:
          elements_count[element] = 1
    return elements_count

"""### Part c)"""

new_ind = np.random.choice(range(len(olive_data.data)), size=40)
centre = olive_data.data[new_ind]
model = Kmeans_scratch_ver2(k=40,init_centres = centre)
model.fit(olive_data.data)
centres,centres_ind = model.predict(olive_data.data)
print(model.count_of_points())

"""### Part d)"""

centres = np.array(centres)
centres  = centres.reshape((-1,64,64))
fig, axes = plt.subplots(5, 8, figsize=(12, 6))
for i, ax in enumerate(axes.flat):
    ax.imshow(centres[i], cmap='gray')
    ax.set_title(i)
    ax.axis('off')
plt.show()

"""### Part e)"""

# print(centres_ind)
# cluster_indices = np.where(centres_ind == i)[0]

fig, axes = plt.subplots(40, 10, figsize=(10, 40))
centres_ind =np.array(centres_ind)
for i in range(40):
    cluster_indices = np.where(centres_ind == i)[0]
    sample_indices = np.random.choice(cluster_indices,10)
    if(len(cluster_indices) < 10):
      sample_indices = np.random.choice(cluster_indices,len((cluster_indices)))
    for j, index in enumerate(sample_indices):
        img = olive_data.images[index]
        axes[i, j].imshow(img, cmap='gray')
        axes[i, j].axis('off')
        axes[i,j].set_title(str(i))


plt.show()

fig, axes = plt.subplots(40, 10, figsize=(10, 40))
centres_ind =np.array(centres_ind)
for i in range(40):
    cluster_indices = np.where(centres_ind == i)[0]
    sample_indices =np.random.choice(cluster_indices,10)
    for j, index in enumerate(sample_indices):
        img = olive_data.images[index]
        axes[i, j].imshow(img, cmap='gray')
        axes[i, j].axis('off')
        axes[i,j].set_title(str(i))


plt.show()

"""### Part f)"""

class_init = np.concatenate([olive_data.data[np.where(olive_data.target == i)[0][:1]] for i in range(40)])
model_img = Kmeans_scratch_ver2(k=40,init_centres = class_init)
model_img.fit(olive_data.data)
centres,centres_ind = model_img.predict(olive_data.data)
centres = np.array(centres)
print(model_img.count_of_points())
class_centers = centres.reshape((-1, 64, 64))


# Plot cluster centers
fig, axes = plt.subplots(5, 8, figsize=(12, 6))
for i, ax in enumerate(axes.flat):
    ax.imshow(class_centers[i], cmap='gray')
    ax.axis('off')
    ax.set_title(i)
plt.show()

"""### Part g)"""

fig, axes = plt.subplots(40, 10, figsize=(10, 40))
centres_ind =np.array(centres_ind)
for i in range(40):
    cluster_indices = np.where(centres_ind == i)[0]
    sample_indices = np.random.choice(cluster_indices, 10)
    if(len(cluster_indices) < 10):
      sample_indices = np.random.choice(cluster_indices, len(cluster_indices))
    for j, index in enumerate(sample_indices):
        img = olive_data.images[index]
        axes[i, j].imshow(img, cmap='gray')
        axes[i, j].axis('off')
        axes[i,j].set_title(str(i))
plt.show()

fig, axes = plt.subplots(40, 10, figsize=(10, 40))
centres_ind =np.array(centres_ind)
for i in range(40):
    cluster_indices = np.where(centres_ind == i)[0]
    sample_indices = np.random.choice(cluster_indices, 10)
    for j, index in enumerate(sample_indices):
        img = olive_data.images[index]
        axes[i, j].imshow(img, cmap='gray')
        axes[i, j].axis('off')
        axes[i,j].set_title(str(i))
plt.show()

"""### Part h)"""

distances = np.linalg.norm(olive_data.data[:, np.newaxis, :] - model.centres_of_points, axis=2)
sse1 = np.sum(np.min(distances, axis=1)**2)

# Compute SSE for new KMeans model
class_distances = np.linalg.norm(olive_data.data[:, np.newaxis, :] - model_img.centres_of_points, axis=2)
sse2 = np.sum(np.min(class_distances, axis=1)**2)

print(f"SSE for original KMeans model: {sse1}")
print(f"SSE for new KMeans model: {sse2}")

"""## Problem 3

### Part a)
"""

dataset = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/00292/Wholesale%20customers%20data.csv")
dataset

copyset = dataset.copy()
copyset.info()

scaled_dataset = StandardScaler().fit_transform(copyset)
scaled_dataset = pd.DataFrame(data = scaled_dataset, columns = dataset.columns)
scaled_dataset

"""### Part b)"""

covariance_mat = scaled_dataset.cov()
max_val = 0
features_1 = ""
features_2 = ""
cols = scaled_dataset.columns
for i in list(cols):
  for j in list(cols):
    if( i == j):
      continue
    else:
      if(max_val < abs(covariance_mat[i][j])):
        max_val = abs(covariance_mat[i][j])
        features_1 = i
        features_2 = j
print(features_1,features_2,max_val)
covariance_mat

sns.scatterplot(x = features_1,y=features_2,data = scaled_dataset)

plt.rcParams["figure.figsize"] = (20,10)
sns.barplot(x = features_2,y=features_1,data = scaled_dataset)

"""### Part c)"""

model_dbscan = DBSCAN()
clusters = model_dbscan.fit_predict(scaled_dataset)
fig = plt.figure(figsize =(24, 28))
cnt = 0
for j in range(len(cols)):
  for k in range(j,len(cols)):
    if(j == k):
      continue
    else:
      cnt += 1
      ax = fig.add_subplot(4, 7, cnt)
      sns.scatterplot(x = scaled_dataset[cols[j]], y = scaled_dataset[cols[k]],hue = clusters,palette='bright',ax= ax)
      ax.set_xlabel(cols[j])
      ax.set_ylabel(cols[k])
plt.show()

"""### Part d)"""

models_kmeans = KMeans()
clusters = models_kmeans.fit_predict(scaled_dataset)
fig = plt.figure(figsize =(24, 28))
cnt = 0
for j in range(len(cols)):
  for k in range(j,len(cols)):
    if(j == k):
      continue
    else:
      cnt += 1
      ax = fig.add_subplot(4, 7, cnt)
      sns.scatterplot(x = scaled_dataset[cols[j]], y = scaled_dataset[cols[k]],hue = clusters,palette='bright',ax= ax)
      ax.set_xlabel(cols[j])
      ax.set_ylabel(cols[k])
plt.show()

"""### Part e)"""

dataset_moons = make_moons(n_samples = 2000,noise = 0.2)
df_moons = pd.DataFrame(data = dataset_moons[0],columns = ["X1","X2"])
df_moons

plt.rcParams["figure.figsize"] = (7,7)
sns.scatterplot(x = "X1" , y = "X2",data = df_moons,hue = dataset_moons[1])

fig = plt.figure(figsize =(20, 15))
for i in range(5,15):
  model_dbscan_2 = DBSCAN(eps=0.08 ,min_samples=i)
  cols = df_moons.columns
  clusters = model_dbscan_2.fit_predict(df_moons)
  # print(clusters)
  for j in range(len(cols)):
    for k in range(j,len(cols)):
      if(j == k):
        continue
      else:
        ax = fig.add_subplot(2, 5, i-4)
        sns.scatterplot(x = df_moons[cols[j]], y = df_moons[cols[k]],hue = clusters,palette='bright')
        plt.xlabel(cols[j])
        plt.ylabel(cols[k])
        plt.title(str(i))
plt.show()

model_kmeans_2 = KMeans(n_clusters = 2,n_init = 10)
cols = df_moons.columns
clusters = model_kmeans_2.fit_predict(df_moons)
print(clusters)
fig = plt.figure(figsize =(5, 5))
cnt = 0
for j in range(len(cols)):
  for k in range(j,len(cols)):
    if(j == k):
      continue
    else:
      cnt += 1
      ax = fig.add_subplot(1, 1, cnt)
      sns.scatterplot(x = df_moons[cols[j]], y = df_moons[cols[k]],hue = clusters,palette='bright',ax= ax)
      ax.set_xlabel(cols[j])
      ax.set_ylabel(cols[k])
plt.show()